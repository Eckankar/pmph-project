\documentclass[a4paper]{article}
\usepackage{a4wide}

\usepackage[danish,english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[protrusion=true,expansion=true,final]{microtype}
\usepackage[T1]{fontenc}
\usepackage[sc]{mathpazo}

\usepackage{hyperref}
\usepackage{booktabs}

\usepackage{todonotes}

\usepackage{subfig}
\newcommand{\subfigureautorefname}{\figureautorefname}
\newcommand{\subtableautorefname}{\tableautorefname}
\usepackage[margin=10pt,font=footnotesize,labelfont=bf]{caption}

\usepackage{textcomp}
\usepackage{listingsutf8}
\lstset{
    keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
    identifierstyle=\ttfamily,
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
    showstringspaces=false,
    basicstyle=\footnotesize\ttfamily,
    numbersep=10pt,
    tabsize=2,
    breaklines=true,
    prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    breakatwhitespace=false,
    aboveskip={1.5\baselineskip},
    columns=fixed,
    extendedchars=true,
    frame=single,
    captionpos=b,
    language=C++
}

\title{Programming Massively Parallel Hardware \\ Group Project}
\author{Sebastian Paaske TÃ¸rholm \and Daniel Egeberg}

\begin{document}
\maketitle

\section{Loop accesses}
\label{sec:loop}

\subsection{\texttt{run\_OrigCPU}}

Contains a single loop that can be parallelized by privatizing \texttt{strike} and \texttt{globs}.

\subsection{\texttt{value}}

The loop in this function is not parallelizable. It loops over time steps, and
calls \texttt{rollback}, which uses results from previous time steps. This is
sequential in nature.

\subsection{\texttt{updateParams}}

Already parallelizable as each iteration step is independent.

\subsection{\texttt{rollback}}

Contains four outer loops:
\begin{enumerate}
    \item Already parallelizable as it writes to \texttt{u[j][i]} without reading from \texttt{u}.
    \item Already parallelizable as it writes to \texttt{v[i][j]} and \texttt{u[j][i]} without reading from \texttt{v} or \texttt{u} for different indices.
    \item The inner loop is already parallelizable as it writes to separate indices of \texttt{a}, \texttt{b} and \texttt{c}. The outer loop cannot be parallelized as it calls \texttt{tridag}, which rewrites \texttt{u} based on previous iterations.
    \item The inner loop is already parallelizable as it writes to separate indices of \texttt{a}, \texttt{b}, \texttt{c} and \texttt{y}. The outer loop can, unlike the previous loop, be parallelized by privatizing the aforementioned variables. This is possible because we write to \texttt{myResult} based on \texttt{y} (which is local).
\end{enumerate}

\subsection{\texttt{tridag}}

This can be parallelized by changing the algorithm to the one mentioned in the lectures.


\section{OpenMP implementation}

This is done by privatizing the loop in \texttt{run\_OrigCPU} as described in
\autoref{sec:loop}. Doing this we can just add \autoref{lst:ompPragma} to the
outer loop as suggested.\todo{Argue why this is valid.}

\begin{lstlisting}[caption={bla bla},label={lst:ompPragma}]
#pragma omp parallel for default(shared) schedule(static) if(outer>4)
\end{lstlisting}


\section{CUDA implementation}

\subsection{Moving out the time loop}

As we observed in \autoref{sec:loop}, the time loop is sequential, so we want
this as our outermost loop. We start by inlining the \texttt{value} function in
the run function. This enables us to perform this rewrite. From this, we can
observe that \texttt{updateParams} and \texttt{rollback} are the only
operations that depend on the time step. Thus, we can factor out all other
operations in a parallelizable loop by maintaining a separate \texttt{globs}
struct per ``\texttt{outer}''.

\subsection{Converting from STL vectors}

The original implementation uses the \texttt{PrivGlobs} struct, which is
implemented using vectors from C++ STL\@. We cannot use things from STL in a
CUDA kernel, and in particular, we cannot use the vectors as they use dynamic
resizing, while dynamic memory allocation is not possible in a CUDA kernel.
This requires us to use arrays directly. We replace the \texttt{PrivGlobs}
array with the individual fields extended with the \texttt{outer} dimension.
This means that \autoref{lst:vector1} can be rewritten to
\autoref{lst:vector2}.

\begin{lstlisting}[caption={An array of \texttt{PrivGlobs}.},label={lst:vector1}]
PrivGlobs globs[outer];
\end{lstlisting}
\begin{lstlisting}[caption={Expanding the struct.},label={lst:vector2}]
REAL myX[outer][numX];
REAL myY[outer][numY];
// ...
\end{lstlisting}

\subsection{Eliminate duplicate computations}
\label{sec:eliminate_dup_comp}

Many variables are only written to once after the initial write (see
\autoref{tbl:rw}), and are not a function of \texttt{outer}'s iteration
variable. This allows to move these computations outside the outer loop. An
example of such a transformation is \autoref{lst:duplicate1} to
\autoref{lst:duplicate2}. This kind of transformation is valid for
\texttt{myX}, \texttt{myY}, \texttt{myTimeline}, \texttt{myDxx} and
\texttt{myDyy}. This saves computation time and memory.

\begin{table}
    \centering
    \begin{tabular}{lcccccccc}
        \toprule
        \textbf{Function}             & \texttt{myX} & \texttt{myY} & \texttt{myTimeline} & \texttt{myResult} & \texttt{myVarX} & \texttt{myVarY} & \texttt{myDxx} & \texttt{myDyy} \\
        \midrule
        \texttt{initGrid}             & W            & W            & W                   &                   &                 &                 &                &                \\
        \texttt{initOperator}, x      & R            &              &                     &                   &                 &                 & W              &                \\
        \texttt{initOperator}, y      &              & R            &                     &                   &                 &                 &                & W              \\
        \texttt{setPayoff}            & R            &              &                     & W                 &                 &                 &                &                \\
        \texttt{updateParams}         & R            & R            & R                   &                   & W               & W               &                &                \\
        \texttt{rollback}, explicit x &              &              &                     & R                 & R               &                 & R              &                \\
        \texttt{rollback}, explicit y &              &              &                     & R                 &                 & R               &                & R              \\
        \texttt{rollback}, implicit x &              &              &                     &                   & R               &                 & R              &                \\
        \texttt{rollback}, implicit y &              &              &                     & W                 &                 & R               &                & R              \\
        \bottomrule
    \end{tabular}
    \caption{Reads and writes in global variables.}
    \label{tbl:rw}
\end{table}

\begin{lstlisting}[caption={bla bla},label={lst:duplicate1}]
REAL myX[outer][numX];
REAL myY[outer][numY];
// ...
for (unsigned i = 0; i < outer; ++i) {
    initGrid(..., i, myX, myY, numX, numY, ...);
    // ...
}
\end{lstlisting}
\begin{lstlisting}[caption={bla bla},label={lst:duplicate2}]
REAL myX[numX];
REAL myY[numY];
// ...
initGrid(..., myX, myY, numX, numY, ...);
// ...
\end{lstlisting}

\subsection{Converting to kernels}

Each line in \autoref{tbl:rw} gets converted to a separate CUDA kernel taking
the parameters where it has read/write operations. Here we need to take special
care of \texttt{rollback} as it has a number of local variables that are shared
across the different subparts of the function. These are \texttt{u} and
\texttt{v}, and their read/write operations are outlined in
\autoref{tbl:rw_rollback}.

This logically represents splitting up the outer loop, i.e.\ doing the
transformation \autoref{lst:splitting1} to \autoref{lst:splitting2}. This
transformation is valid as there are no dependencies across \texttt{outer}
iterations and the results are saved per iteration, except where the results
are identical each iteration as shown in \autoref{sec:eliminate_dup_comp}.

\begin{lstlisting}[caption={bla bla},label={lst:splitting1}]
for (unsigned i = 0; i < outer; ++i) {
    updateparams(...);
    rollback_explicit_x(...);
    // ...
}
\end{lstlisting}
\begin{lstlisting}[caption={bla bla},label={lst:splitting2}]
for (unsigned i = 0; i < outer; ++i) {
    updateparams(...);
}
for (unsigned i = 0; i < outer; ++i) {
    rollback_explicit_x(...);
}
for (unsigned i = 0; i < outer; ++i) {
    // ...
}
\end{lstlisting}

\begin{table}
    \centering
    \begin{tabular}{lccccccc}
        \toprule
        \textbf{Function}             & \texttt{u} & \texttt{v} & \texttt{myResult} & \texttt{myVarX} & \texttt{myVarY} & \texttt{myDxx} & \texttt{myDyy} \\
        \midrule
        \texttt{rollback}, explicit x & W          &            & R                 & R               &                 & R              &                \\
        \texttt{rollback}, explicit y & RW         & W          & R                 &                 & R               &                & R              \\
        \texttt{rollback}, implicit x & RW         &            &                   & R               &                 & R              &                \\
        \texttt{rollback}, implicit y & R          & R          & W                 &                 & R               &                & R              \\
        \bottomrule
    \end{tabular}
    \caption{Reads and writes for \texttt{rollback}.}
    \label{tbl:rw_rollback}
\end{table}

Seeing as we cannot pass real multi-dimensional arrays to CUDA kernels, we have
to create one-dimensional arrays and calculate the index manually based on
their coordinates dimension sizes. For this we have created the macros in
\autoref{lst:idx_macro}.

\begin{lstlisting}[caption={Calculating array indices.},label={lst:idx_macro}]
#define IDX2(DIMX, DIMY, X, Y)           ((X)*(DIMY) + (Y))
#define IDX3(DIMX, DIMY, DIMZ, X, Y, Z)  ((X)*(DIMY)*(DIMZ) + (Y)*(DIMZ) + (Z))
\end{lstlisting}

\subsection{Coalescing memory accesses}

% XXX

\subsection{Optimizing tridag}

% XXX

\end{document}
